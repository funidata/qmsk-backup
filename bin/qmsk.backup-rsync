#!/usr/bin/python3

"""
    Backup rsync sources into rsync --link-dest snapshots.
"""

import datetime
import json
import logging
import os
import os.path
import qmsk.args
import shutil
import stat

from qmsk.backup import __version__
from qmsk.backup.target import Interval, BaseTarget

log = logging.getLogger('qmsk.backup-target')

class Error(Exception):
    pass

def walk_symlinks (tree, recurse=0, ignore=False) :
    """
        Walk through all symlinks in given dir, yielding:

            (path, target)

        Passes through errors from os.listdir/os.lstat.
    """

    for name in os.listdir(tree):
        if name.startswith('.'):
            log.debug("%s: ignore dotfile: %s", tree, name)
            continue

        if ignore and name in ignore:
            log.debug("%s: ignore: %s", tree, name)
            continue

        path = os.path.join(tree, name)

        # stat symlink itself
        st = os.lstat(path)

        if stat.S_ISDIR(st.st_mode):
            # recurse
            log.debug("%s: tree: %s", tree, name)

            if recurse > 0:
                for path, target in walk_symlinks(path,
                        recurse = recurse - 1,
                        ignore  = ignore,
                ):
                    yield path, target

        elif stat.S_ISLNK(st.st_mode):
            # found
            target = os.path.normpath(os.path.join(tree, os.readlink(path)))

            log.debug("%s: link: %s -> %s", tree, name, target)

            yield path, target

        else :
            log.debug("%s: skip: %s", tree, name)

class Target(BaseTarget):
    """
        Use rsync hardlinks for incremental snapshots, and symlinks to manage intervals.
    """

    @classmethod
    def config (cls, path,
            **opts
    ):
        return super().config(
                path            = path,
                **opts
        )

    def __init__ (self, path, noop=None, **opts):
        super().__init__(**opts)

        self.noop = noop

        self.path = os.path.abspath(path)
        self.snapshots_path = os.path.join(self.path, 'snapshots')
        self.snapshot_path = os.path.join(self.path, 'snapshot')

    def __str__ (self):
        return str(self.path)

    def setup (self, create=False):
        """
            Verify that the destination tree exists.
        """

        if os.path.exists(self.path):
            pass
        elif create:
            log.warning("Create target directory: %s", self.path)

            os.mkdir(self.path)
        else:
            raise Error("Missing target directory: {path}".format(path=self.path))

        if os.path.exists(self.snapshots_path):
            pass
        elif create:
            log.warn("Creating snapshots directory: %s", self.snapshots_path)
            os.mkdir(self.snapshots_path)
        else:
            raise Error("Missing snapshots directory: {path}".format(path=self.snapshots_path))

        # TODO: rename current -> snapshot

    def snapshot (self, now):
        """
            Update the current snapshot to point to a new snapshot for the given datetime, containing changes from rsync.

            Returns the name of the new snapshot on completion.

            Raises rsync.RsyncError or Error.
        """

        # new snapshot
        snapshot_name = now.strftime(self.SNAPSHOT_STRFTIME)
        snapshot_path = os.path.join(self.snapshots_path, snapshot_name)

        if os.path.exists(snapshot_path):
            raise Error("Snapshot already exists: {path}".format(path=snapshot_path))

        if os.path.exists(self.snapshot_path):
            # link-dest from previous snapshot
            target_path = os.path.join(os.path.dirname(self.snapshot_path), os.readlink(self.snapshot_path))

            # use as link-dest base; hardlinks unchanged files; target directory must be empty
            link_dest = target_path

        else :
            link_dest = None

        # log
        log.info("%s: snapshot %s with link_dest=%s", self, snapshot_name, link_dest)

        # rsync
        new_path = snapshot_path + '.new'
        meta_path = snapshot_path + '.meta'

        log.debug("%s: rsync %s -> %s --link-dest=%s", self, self.rsync_source, new_path, link_dest)

        meta = {
                'rsync_source': str(self.rsync_source),
                'link_dest':    link_dest,
                'start':        datetime.datetime.utcnow().isoformat(),
        }

        try:
            stats = self.rsync(new_path,
                    link_dest   = link_dest,
            )

        except qmsk.backup.rsync.Error as ex:
            # leave the .new snapshot in place to be purged
            log.warning("%s: rsync failed: %s", ex)

            # run() handles this
            raise

        else:
            meta['end'] = datetime.datetime.utcnow().isoformat()

            # move in to final name
            log.debug("rename %s -> %s", new_path, snapshot_path)
            os.rename(new_path, snapshot_path)

            # write stats
            if stats:
                meta['stats'] = stats

        # write out stats
        log.debug("write out meta file: %s", meta_path)

        json.dump(meta, open(meta_path, 'w'))

        # update snapshot
        symlink = os.path.join('snapshots', snapshot_name)

        log.debug("symlink %s <- %s", symlink, self.snapshot_path)

        if os.path.islink(self.snapshot_path):
            os.unlink(self.snapshot_path)

        os.symlink(symlink, self.snapshot_path)

        return snapshot_name

    def backup_interval (self, interval, now, snapshot_name, setup_create=False):
        """
            Create interval symlinks for managing retention of the given snapshot.

            Intervals that already have a snapshot are skipped.
        """

        snapshot_path = os.path.join(self.path, 'snapshots', snapshot_name)

        # setup
        dir_path = os.path.join(self.path, interval.name)

        if os.path.isdir(dir_path):
            pass
        elif setup_create:
            log.warning("create interval dir: %s", dir_path)
            os.mkdir(dir_path)
        else:
            raise Error("Interval directory {dir} is missing, use --setup-create?".format(dir=dir_path))

        # prepare
        name = interval.format(now)
        path = os.path.join(dir_path, name)

        if not os.path.exists(path):
            log.info("create interval: %s/%s -> %s", interval.name, name, snapshot_name)
            os.symlink(snapshot_path, path)
        else:
            log.info("skip interval %s/%s -> %s", interval.name, name, os.readlink(path))

    def iter_snapshots (self):
        """
            Yield (snapshot_name) of found snapshots.
        """

        for name in os.listdir(self.snapshots_path):
            path = os.path.join(self.snapshots_path, name)

            if name.startswith('.'):
                log.warning("Ignore dotfile in snapshots dir: %s", name)
                continue

            if not os.path.isdir(path):
                log.debug("Ignore non-directory in snapshots dir: %s", name)
                continue

            if name.endswith('.new'):
                snapshot_name = name[:-4]
            else:
                snapshot_name = name

            try:
                when = datetime.datetime.strptime(snapshot_name, self.SNAPSHOT_STRFTIME)
            except ValueError as error:
                raise Error("Invalid snapshot %s found: %s", name, error)

            yield name

    def iter_interval_snapshots (self, tree, **opts):
        """
            Yield (snapshot_name, path) of found snapshot symlinks from given dir.
        """

        for path, target_path in walk_symlinks(tree, **opts):
            # read snapshot target
            target_dir, target_name = os.path.split(target_path)

            if target_dir != self.snapshots_path:
                raise Error("Invalid symlink to non-snapshot: %s -> %s", path, target_path)
            else:
                snapshot_name = target_name

            yield snapshot_name, path

    def purge_interval (self, interval):
        """
            Purge any extra interval symlinks over the configured limit.
        """

        interval_dir = os.path.join(self.path, interval.name)

        snapshots = list(self.iter_interval_snapshots(interval_dir))

        # preserve most recent snapshots, sorting by the snapshot_name descending, i.e. most recent snapshots first
        snapshots.sort(reverse=True)

        purge_snapshots = snapshots[interval.limit:]

        for snapshot_name, interval_path in purge_snapshots:
            log.info("Purging interval %s/%s: %s", interval.name, os.path.basename(interval_path), snapshot_name)

            if self.noop:
                log.warning("os.unlink(%r)", interval_path)
            else:
                os.unlink(interval_path)

    def backup (self, setup_create=None, purge=None):
        """
            Run backup, managing snapshots.
        """

        # start
        now = datetime.datetime.now()

        snapshot = self.snapshot(now)

        for interval in self.intervals:
            self.backup_interval(interval, now, snapshot,
                    setup_create    = setup_create,
            )

            if purge:
                self.purge_interval(interval)

    def purge_snapshot(self, name):
        """
            Purge given snapshot.
        """

        path = os.path.join(self.snapshots_path, name)
        meta_path = path + '.meta'

        log.info("Purging snapshot %s: %s", name, path)

        if os.path.exists(meta_path):
            if self.noop:
                log.warning("os.unlink(%r)", meta_path)
            else:
                os.unlink(meta_path)

        if self.noop:
            log.warning("shutil.rmtree(%r)", path)
        else:
            shutil.rmtree(path)

    def purge (self):
        """
            Purge unlinked snapshots.
        """

        # list all snapshots
        snapshots = set(self.iter_snapshots())

        # list all snapshot links
        interval_snapshots = list(self.iter_interval_snapshots(self.path, recurse=1, ignore={'snapshots'}))

        for snapshot_name, interval_path in interval_snapshots:
            if snapshot_name not in snapshots:
                log.warning("Missing snapshot %s: %s", snapshot_name, interval_path)
            else:
                log.debug("found snapshot %s: %s", snapshot_name, interval_path)

        # purge unlinked snapshots
        linked_snapshots = {snapshot_name for snapshot_name, interval_path in interval_snapshots}

        for snapshot_name in sorted(snapshots & linked_snapshots):
            log.debug("Keeping snapshot %s", snapshot_name)

        for snapshot_name in snapshots - linked_snapshots:
            self.purge_snapshot(snapshot_name)

    def meta(self):
        """
            Yield (name, meta) for snapshots/*.met
        """

        for snapshot in sorted(self.iter_snapshots()):
            path = os.path.join(self.snapshots_path, snapshot + '.meta')

            if os.path.exists(path):
                with open(path) as file:
                    meta = json.load(file)

                yield snapshot, meta

META_TIMESTAMP_STRFTIME = '%Y-%m-%dT%H:%M:%S.%f'

def meta_duration(meta):
    """
        Return datetime.timedelta from meta dict.
    """

    start = datetime.datetime.strptime(meta['start'], META_TIMESTAMP_STRFTIME)
    end = datetime.datetime.strptime(meta['end'], META_TIMESTAMP_STRFTIME)

    return end - start

def main (args):
    parser = qmsk.args.parser(package='backup', module='target',
            description = __doc__,
            version     = __version__,
    )

    parser.add_argument('-n', '--noop', action='store_true',
            help="No-op")
    parser.add_argument('--sudo', action='store_true',
            help="Run rsync via sudo")

    parser.add_argument('--setup-create', action='store_true',
            help="Setup new backup destination")

    parser.add_argument('--rsync-source', metavar='RSYNC-SOURCE',
            help="Backup rsync source")
    parser.add_argument('--rsync-option', metavar='-option', action='append', dest='rsync_options', default=[],
            help="Pass rsync options")

    parser.add_argument('--no-backup', action='store_false', dest='backup',
            help="Skip backup snapshot (and purge)")
    parser.add_argument('--interval', metavar=Interval.METAVAR, action='append', dest='intervals', type=Interval.config, default=[],
            help="Backup retention intervals")
    parser.add_argument('--purge', action='store_true',
            help="Purge old snapshots")
    parser.add_argument('--stats', action='store_true',
            help="Output stats from snapshots")

    parser.add_argument('target', metavar='PATH', nargs='+',
            help="rsync target directory")

    parser.set_defaults(
            backup      = None,
    )

    args = qmsk.args.parse(parser, args)

    for target in args.target:
        try:
            target = Target.config(target,
                    rsync_source    = args.rsync_source,
                    rsync_options   = args.rsync_options,
                    intervals       = args.intervals,
                    noop            = args.noop,
                    sudo            = args.sudo,
            )
        except Error as error:
            log.error("%s: %s", target, error)
            return 1
        else:
            log.info("%s", target)

        try:
            target.setup(
                    create          = args.setup_create,
            )

            if args.backup is False:
                log.debug("Skip backup")
            else:
                target.backup(
                        setup_create    = args.setup_create,
                        purge           = args.purge,
                )

            # purge snapshots
            if args.purge:
                target.purge()

            if args.stats:
                qmsk.backup.rsync.print_stats([(name, meta_duration(meta), meta['stats']) for name, meta in  target.meta()])

        except Error as error:
            log.exception("%s: %s", target, error)
            return 2

    return 0

if __name__ == '__main__':
    qmsk.args.main(main)
